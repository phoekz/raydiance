<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>raydiance - blog</title>
    <style>
        a {
            color: darkorange;
            text-decoration: none;
        }

        .title {
            border-bottom: 1px solid #bbb
        }

        section {
            max-width: 800px;
            margin: 0 auto;
        }

        article {
            margin: 30px 0 5px 0;
            border-bottom: 1px solid #bbb
        }

        .article-date {
            margin: 20px 0;
            color: #666;
        }
    </style>
</head>

<body>
    <section>
        <!-- Header -->
        <div class="title">
            <h1>raydiance - blog</h1>
        </div>

        <!-- Posts -->
        <article>
            <h2>Adding multisampled anti-aliasing (MSAA)</h2>
            <div class="article-date">2023-01-10</div>

            <img src="images/20230110-001539.png">

            <p>
                This was pretty easy. Similarly to depth buffer, we create a new
                color buffer which will be multisampled. The depth buffer is
                also updated to support multisampling. Then we update all the
                <code>resolve*</code> fields in <a
                    href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VkRenderingAttachmentInfo.html"><code>VkRenderingAttachmentInfo</code></a>,
                and finally we add multisampling state to our pipeline. No more
                jagged edges.
            </p>

            <p>
                Commit:
                <code>
                    <a href="https://github.com/phoekz/raydiance/commit/ca2a23caaa5e9d9b321a50389af492fbc708b560">ca2a23ca</a>
                </code>
            </p>
        </article>

        <article>
            <h2>More triangles, cameras, light, and depth</h2>
            <div class="article-date">2023-01-09</div>

            <img src="images/20230109-181800.webp">

            <p>
                A lot has happened since our single hardcoded triangle. We can
                now render shaded, depth tested, transformed, indexed triangle
                lists, with perspective projection.
            </p>

            <h3>Loading and rendering GLTF scenes</h3>

            <img src="images/20230109-182433.png">

            <p>
                We created a simple "cube on a plane" scene in Blender. Each
                object has a "Principled BSDF" material attached to it. This
                material is <a
                    href="https://docs.blender.org/manual/en/latest/addons/import_export/scene_gltf2.html#extensions">well
                    supported</a> by Blender's GLTF exporter, which is what we will
                use for our application. GLTF supports text formats, but we will
                export the scene in binary (<code>.glb</code>) for efficiency.
            </p>

            <p>
                To load the <code>.glb</code> file, we use <a href="https://crates.io/crates/gltf"><code>gltf</code></a>
                crate. Immediately after loading, we pick out the interesting
                fields (cameras, meshes, materials) and convert them into our
                <a
                    href="https://github.com/phoekz/raydiance/blob/cb1bcc1975e3860b7208cffb4286fec3e91cc5d2/src/assets.rs#L3-L35">internal
                    data format</a>. This internal format is designed to be easy to
                upload to the GPU. We also do aggressive validation in order to
                catch any properties that we don't support yet, such as
                textures, meshes that do not have normals, and so on. Our
                internal formats represent matrices and vectors with types from
                <a href="https://crates.io/crates/nalgebra"><code>nalgebra</code></a>
                crate. To turn our internal formats into byte slices <a
                    href="https://crates.io/crates/bytemuck"><code>bytemuck</code></a> crate.
            </p>

            <p>
                Before we can render, we need to upload geometry data to the
                GPU. For now, we assume the number of meshes is much less than
                4096 (on most Windows hosts the <a
                    href="https://vulkan.gpuinfo.org/displaydevicelimit.php?platform=windows&name=maxMemoryAllocationCount"><code>maxMemoryAllocationCount</code></a>
                is 4096). This allows us to cheat and allocate buffers for each
                mesh. The better way to handle allocations is make a few large
                allocations and sub-allocate within those, which we can do
                ourselves, or use a library like <a
                    href="https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator"><code>VulkanMemoryAllocator</code></a>.
                We will come back to memory allocators in the future.
            </p>

            <p>
                To render, we will have to work out the perspective projection,
                the view transform and object transforms from GLTF. We also add
                rotation transform to animate the cube. We pre-multiply all
                transforms and upload the final matrix to the vertex shader
                using <a
                    href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/vkspec.html#descriptorsets-push-constants">push
                    constants</a>. The base color of the mesh is also packed into a
                push constant. Push constants are great for small data, because
                we can avoid:
            </p>

            <ol>
                <li>Descriptor set layouts, descriptor pools, descriptor sets</li>
                <li>Uniform buffers, which would have to be double buffered to avoid stalls</li>
                <li>Synchronizing updates to uniform buffers</li>
            </ol>

            <p>
                As a side, while looking into push constants, we learned about
                <a
                    href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/vkspec.html#VK_KHR_push_descriptor"><code>VK_KHR_push_descriptor</code></a>.
                This extension sounds like it could further simplify working
                with Vulkan, which is really exciting. We will come back to it
                in the future once we get into texture mapping.
            </p>

            <h3>Depth testing with <code>VK_KHR_dynamic_rendering</code></h3>

            <img src="images/20230109-190941.png">

            <p>
                Depth testing requires a depth texture, which we create at
                startup, and re-create when the window changes size. To enable depth testing with
                <code>VK_KHR_dynamic_rendering</code>, we had to extend our
                graphics pipeline with a new structure called
                <a
                    href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/vkspec.html#VkPipelineRenderingCreateInfo"><code>VkPipelineRenderingCreateInfo</code></a>,
                and also add color blend state which was previously left out.
                One additional pipeline barrier was required to transition the
                depth texture for rendering.
            </p>

            <p>
                Commit:
                <code>
                    <a href="https://github.com/phoekz/raydiance/commit/cb1bcc1975e3860b7208cffb4286fec3e91cc5d2">cb1bcc19</a>
                </code>
            </p>

        </article>

        <article>
            <h2>The first triangle</h2>
            <div class="article-date">2023-01-08</div>

            <img src="images/20230108-193100.webp">

            <p>
                This is the simplest triangle example rendered without any
                device memory allocations. The triangle is hard coded in the
                vertex shader and we index into its attributes with vertex
                index.
            </p>

            <p>
                We added a simple shader compiling step in
                <a href="https://doc.rust-lang.org/cargo/reference/build-scripts.html"><code>build.rs</code></a>
                which builds
                <code>.glsl</code> into <code>.spv</code> using Google's <a
                    href="https://github.com/google/shaderc/tree/main/glslc"><code>glslc</code></a>,
                which is included in <a href="https://vulkan.lunarg.com/sdk/home">LunarG's Vulkan
                    SDK</a>.
            </p>

            <p>
                Next we will implement device memory allocations in order to
                load a 3D model from a file.
            </p>

            <p>
                Commit:
                <code>
                    <a href="https://github.com/phoekz/raydiance/commit/c8f9ef2c0f3b51ddfd71f33ec086fca1531051ab">c8f9ef2c</a>
                </code>
            </p>

        </article>

        <article>
            <h2>Clearing window with <code>VK_KHR_dynamic_rendering</code></h2>
            <div class="article-date">2023-01-08</div>

            <img src="images/20230108-170100.webp">

            <p>
                After around 1000 LOC, we have a barebones Vulkan application which:
            </p>

            <ol>
                <li>Load Vulkan with <a href="https://crates.io/crates/ash"><code>ash</code></a> crate.</li>
                <li>Creates Vulkan instance with <code>VK_LAYER_KHRONOS_validation</code> and debug utilities.</li>
                <li>Creates window surface with <a
                        href="https://crates.io/crates/ash-window"><code>ash-window</code></a>
                    and
                    <a href="https://crates.io/crates/raw-window-handle"><code>raw-window-handle</code></a> crates.
                </li>
                <li>Creates logical device and queues.</li>
                <li>Creates command pool and buffers.</li>
                <li>Creates swapchain.</li>
                <li>Creates semaphores and fences for host to host and host to device synchronization.</li>
                <li>Clears the screen with a different color every frame.</li>
            </ol>

            <p>
                We also handle tricky situations such as user resizing the window and minimizing the window.
            </p>

            <p>
                Notably we are not creating render passes or framebuffers, thanks to
                <code>VK_KHR_dynamic_rendering</code>. We do have to specify some
                render pass parameters when we record command buffers, but reducing
                the number of API abstractions simplifies the implementation
                signifcantly. We used this <a
                    href="https://github.com/SaschaWillems/Vulkan/blob/313ac10de4a765997ddf5202c599e4a0ca32c8ca/examples/dynamicrendering/dynamicrendering.cpp">example</a>
                as a reference.
            </p>

            <p>
                Everything is written under <code>main()</code> with minimal
                abstractions and with liberal use of <code>unsafe</code>. We
                will do a <a href="https://caseymuratori.com/blog_0015">semantic
                    compression</a>
                pass later once we have learned more about how the program should be
                laid out.
            </p>

            <p>
                Next we will continue with more Vulkan code to get a triangle on the screen.
            </p>

            <p>
                Commit:
                <code>
                    <a href="https://github.com/phoekz/raydiance/commit/0f6d7f1bf1b22d1fff43e87080c854eadb3e459d">0f6d7f1b</a>
                </code>
            </p>

        </article>

        <article>
            <h2>Hello, winit!</h2>
            <div class="article-date">2023-01-07</div>

            <img src="images/20230107-161828.png" />

            <p>
                Before anything interesting can happen, we are going to need a window to draw on. We use <a
                    href="https://crates.io/crates/winit"><code>winit</code></a>
                crate for windowing and handling inputs. For convenience, we
                bound the Escape key to close the window and center the window
                in the middle of the primary monitor.
            </p>

            <p>
                For simple logging we use <a href="https://crates.io/crates/log"><code>log</code></a> and <a
                    href="https://crates.io/crates/env_logger"><code>env_logger</code></a>,
                and for application-level error handling we use <a
                    href="https://crates.io/crates/anyhow"><code>anyhow</code></a>.
            </p>

            <p>
                Next we are going to slog through a huge amount of Vulkan
                boilerplate to begin drawing something on our blank window.
            </p>

            <p>
                Commit:
                <code>
                    <a href="https://github.com/phoekz/raydiance/commit/ff4c31c2c6c2039d33bfd07865448da963febfd6">ff4c31c2</a>
                </code>
            </p>
        </article>

        <!-- Footer -->
        <div>
            <p style="float: left"><a href="https://github.com/phoekz/raydiance">GitHub</a></p>
            <p style="text-align: right; float: right">© 2023 Vinh Truong</p>
        </div>
    </section>
</body>

</html>